country = 'US',
land = 'en',
bearer_token
)
View(tweets$text)
tweets <-
get_all_tweets(
query = 'neurodiversity',
start_tweets = '2022-01-01T00:00:00Z',
end_tweets = '2022-02-31T00:00:00Z',
country = 'US',
lang = 'en',
bearer_token
)
tweets <-
get_all_tweets(
query = 'neurodiversity',
start_tweets = '2022-01-01T00:00:00Z',
end_tweets = '2022-02-31T00:00:00Z',
country = 'US',
lang = 'en',
bearer_token)
### LOAD PACKAGE
library(academictwitteR)
set_bearer()
.rs.restartR()
### AFTER RESTART, GET BEARER
get_bearer()
### SET TWITTER BEARER IN .Renviron FILE AND RESTART .rs.restartR()
set_bearer()
### AFTER RESTART, GET BEARER
get_bearer()
### SET TWITTER BEARER IN .Renviron FILE AND RESTART .rs.restartR()
set_bearer()
.rs.restartR()
### AFTER RESTART, GET BEARER
get_bearer()
### QUERY THE TWITTER API
tweets <-
get_all_tweets(
query = 'neurodiversity',
start_tweets = '2022-01-01T00:00:00Z',
end_tweets = '2022-01-05T00:00:00Z',
file = 'test'
)
cat(tweets)
view(tweets)
peak(tweets)
### LOAD PACKAGE
library(academictwitteR)
peak(tweets)
top(tweets)
print(tweets)
### QUERY THE TWITTER API
tweets <-
get_all_tweets(
query = 'neurodiversity',
start_tweets = '2022-01-01T00:00:00Z',
end_tweets = '2022-01-05T00:00:00Z',
data_path = 'home/bear/data/Twitter_API/twitter_data'
bind_tweets = FALSE,
### QUERY THE TWITTER API
tweets <-
get_all_tweets(
query = 'neurodiversity',
start_tweets = '2022-01-01T00:00:00Z',
end_tweets = '2022-01-05T00:00:00Z',
data_path = 'home/bear/data/Twitter_API/twitter_data',
bind_tweets = FALSE,
n = 50
)
### QUERY THE TWITTER API
tweets <-
get_all_tweets(
query = 'neurodiversity',
start_tweets = '2022-01-01T00:00:00Z',
end_tweets = '2022-01-05T00:00:00Z',
data_path = 'home/bear/data/Twitter_API/twitter_data/test_2.rds',
bind_tweets = FALSE,
n = 50
)
### QUERY THE TWITTER API
tweets <-
get_all_tweets(
query = 'neurodiversity',
start_tweets = '2022-01-01T00:00:00Z',
end_tweets = '2022-01-05T00:00:00Z',
file = 'test_2.rds'
data_path = 'home/bear/data/Twitter_API/twitter_data',
### QUERY THE TWITTER API
tweets <-
get_all_tweets(
query = 'neurodiversity',
start_tweets = '2022-01-01T00:00:00Z',
end_tweets = '2022-01-05T00:00:00Z',
file = 'test_2.rds',
data_path = 'home/bear/data/Twitter_API/twitter_data',
bind_tweets = FALSE,
n = 50
)
print(tweets)
### QUERY THE TWITTER API
tweets <-
get_all_tweets(
query = 'neurodiversity',
start_tweets = '2022-01-01T00:00:00Z',
end_tweets = '2022-01-05T00:00:00Z',
#    file = 'test_2.rds',
data_path = 'home/bear/data/Twitter_API/twitter_data/',
bind_tweets = FALSE,
n = 50
)
### QUERY THE TWITTER API
tweets <-
get_all_tweets(
query = 'neurodiversity',
start_tweets = '2022-01-01T00:00:00Z',
end_tweets = '2022-01-05T00:00:00Z',
#    file = 'test_2.rds',
data_path = 'home/bear/data/Twitter_API/neurodiversity_data/',
bind_tweets = FALSE,
n = 50
)
tweets <- bind_tweets(data_path = 'home/bear/data/Twitter_API/neurodiversity_data/')
View(tweets)
View(tweets)
View(tweets[[3]][[1]])
View(tweets$text)
### QUERY THE TWITTER API
tweets <-
get_all_tweets(
query = 'neurodiversity',
start_tweets = '2022-01-01T00:00:00Z',
end_tweets = '2022-01-05T00:00:00Z',
#    file = 'test_2.rds',
data_path = 'data/Twitter_API/neurodiversity_data/',
bind_tweets = FALSE,
n = 50
)
View(tweets)
tweets <- bind_tweets(data_path = 'data/Twitter_API/neurodiversity_data/')
View(tweets)
View(tweets$text)
(3 * pi * 2 - 1)^2 / 106.2022
print('hellow world!')
(3 * pi * 2 - 1)^2 / 106.2022
load("~/data/R_Examples/all_data.RData")
onefactordt<-read.csv('onefactordt.csv')
onefactordt<-read.csv('onefactordt.csv')
hotkeys <- read_excel('R_hotkeys.xlsx')
View(hotkeys)
install.packages('pacman')
onefactordt<-read.csv('onefactordt.csv')
str(onefactordt)
#We can also create data ourselves ####
#Let's make up some fake data to see what happens with NAs
a<-c(3, 2, 4, NA, NA) #these are vectors, assigned to object "a"
a
b<-c(1,-1,1,-1,1)
c<-c(2,1,2,3,4)
#We can also create data ourselves ####
#Let's make up some fake data to see what happens with NAs
a<-c(3, 2, 4, NA, NA) #these are vectors, assigned to object "a"
a
b<-c(1,-1,1,-1,1)
c<-c(2,1,2,3,4)
fakedata<-cbind(a,b,c)
fakedata
#make into dataframe
fakedata<-data.frame(fakedata)
fakedata
# How does R deal with missing? ####
fakedata$mean1and2<-rowMeans(fakedata[,1:2]) #baseR code for calculating means
# across columns. base R comes installed. If you want to use other packages you
# have to install them and load them in each session
fakedata
#but, what happens if we add the na.rm option?
fakedata$mean1and2_narm<-rowMeans(fakedata[,1:2], na.rm = TRUE)
fakedata
#What about R Packages?
# The psych package - seems useful to psychology
install.packages("psych")
library(psych)
keys.list<-list(mean1and2_wscore=c("a","b"))
scores<-scoreItems(keys.list,fakedata)
scores #so, this is printing alpha and some other reliability indices. Can it
describe(scores$scores)
scores$scores
#add to fake data
fakedata<-cbind(fakedata,scores$scores)
#let's compare this with the row means
fakedata
library(help = 'datasets')
library(datasets)
data("BJsales")
force(BJsales)
head('BJsales')
data('JohnsonJohnson')
head('JohnsonJohnson')
pacman(lmSupport)
pacman('lmSupport')
install.packages('lmSupport')
install.packages('pwr')
install.packages('lmSupport')
install.packages('pkgname')
library(tidyverse)
## https://cran.r-project.org/web/packages/lmSupp <- removed from the CRAN
## repositroy
library(pwr)
?QuantPsyc
?broom
?car
install.packages('car')
install.packages("car")
?car
?naniar
install.packages('naniar')
?naniar
install.packages('rsthemes')
install.packages('devtools')
# install.packages("devtools")
devtools::install_github("gadenbuie/rsthemes")
devtools::install_github("gadenbuie/rsthemes")
.rs.restartR()
devtools::install_github("gadenbuie/rsthemes")
install.packages('devtools')
devtools::install_github("gadenbuie/rsthemes")
install.packages(
"rsthemes",
repos = c(gadenbuie = 'https://gadenbuie.r-universe.dev', getOption("repos"))
)
rsthemes::list_rsthemes()
rsthemes::install_rsthemes()
rsthemes::install_rsthemes(include_base16 = TRUE)
rsthemes::list_rsthemes()
rsthemes::try_rsthemes()
install_rstudio_themes(theme = "gruvboxr")
devtools::install_github("max-alletsee/rstudio-themes")
remotes::install_github("tallguyjenks/gruvboxr")
gruvboxr::install_theme()
total.ND <- count_all_tweets(
query= 'neurodiversity',
start_tweets = '2023-01-02T00:00:00Z',
end_tweets = '2023-02-12T00:00:00Z',
bearer_token = get_bearer(),
n= 41,
granularity= 'day',
verbose= T,
lang= 'en',
remove_promoted= T
)
library(academictwitteR)
### AFTER RESTART, GET BEARER
get_bearer()
## 'neurominority', '#neurominority'----
NDAM.2021.NM <- count_all_tweets(
query= 'neurominority', '#neurominority',
start_tweets = '2021-03-01T00:00:00Z',
end_tweets = '2021-03-31T00:00:00Z',
bearer_token = get_bearer(),
n= 31,
granularity= 'day',
verbose= T,
lang= 'en',
remove_promoted= T,
)
NDAM.2021.NM <- sum(NDAM.2021.NM$tweet_count)
NDAM.2021.NM
## 'neurominority', '#neurominority'----
NDAM.2021.NM <- count_all_tweets(
query= 'neurodiversity', '#neurodiversity',
start_tweets = '2021-03-01T00:00:00Z',
end_tweets = '2021-03-31T00:00:00Z',
bearer_token = get_bearer(),
n= 31,
granularity= 'day',
verbose= T,
lang= 'en',
remove_promoted= T,
)
NDAM.2021.NM <- sum(NDAM.2021.NM$tweet_count)
NDAM.2021.NM
recent <- get_all_tweets(
query= 'neurodiversity', '#neurodiversity',
start_tweets = '2023-01-02T00:00:00Z',
end_tweets = '2023-02-12T00:00:00Z',
bearer_token = get_bearer(),
n = 30000,
data_path = '~/data/Twitter_API/neurodiversity_data/010223-021223',
export_query = T,
bind_tweets = F,
page_n = 500,
context_annotations = T,
verbose = T
)
## '#NeurodiversityCelebrationWeek','#NeurodiversityWeek'----
NDAM.NCW <- count_all_tweets(
query= '#NeurodiversityCelebrationWeek','#NeurodiversityWeek',
start_tweets = '2021-03-01T00:00:00Z',
end_tweets = '2021-03-02T00:00:00Z',
bearer_token = get_bearer(),
n= 20,
granularity= "day",
verbose= T,
lang= 'en',
remove_promoted= T,
bind_tweets=T
)
NDAM.NCW
View(NDAM.NCW)
summary(NDAM.NCW)
library(multilevel)
data(bh1996)
glimpse(bh1996$WBEING)
library(tidyverse)
glimpse(bh1996$WBEING)
null.mod <- lme(WBEING~1, random=~1|GRP, data=bh1996, control=list(opt='optim'))
VarCorr(null.mod)
names(bh1996)
library(lattice)
ylab='Well-Being))
xyplot(
WBEING~LEAD|as.factor(GRP),
data=bh1996(1:1582,],
type=c('p','g','r'),
install.packages('languageserver')
x <- c(4, 8, 9, 0, 3, 5)
t.test=(x, mu=6.5)
library(psych)
t.test=(x, mu=6.5)
x
class(x)
t.test=(x, mu=6.5)
?t.test
# ARM5 Longitudinal homework
x <- c(4,8,9,0,3,5)
t.test(x, 6.5)
t.test(x, mu=6.5)
table(freq_plot)
freq_plot <- c(4260, 210231, 95558, 37095, 16478, 7640, 13989, 7428)
table(freq_plot)
glimpse(freq_plot)
library(tidyverse)
glimpse(freq_plot)
glimpse(tab)
tab <- table(freq_plot)
tab <- table(freq_plot)
glimpse(tab)
tab <- as.numeric(table(freq_plot))
glimpse(tab)
freq_plot <- c(4260, 210231, 95558, 37095, 16478, 7640, 13989, 7428)
dates <- c('July','Aug','Sep','Oct','Nov','Dec','Jan','Feb')
tab <- data.frame(freq, dates)
freq <- c(4260, 210231, 95558, 37095, 16478, 7640, 13989, 7428)
dates <- c('Jul','Aug','Sep','Oct','Nov','Dec','Jan','Feb')
tab <- data.frame(freq, dates)
glimpse(tab)
freq_plot <- c(4260, 210231, 95558, 37095, 16478, 7640, 13989, 7428)
freq_plot <- c(4260, 210231, 95558, 37095, 16478, 7640, 13989, 7428)
names(freq_plot) <- c('Jul','Aug','Sep','Oct','Nov','Dec','Jan','Feb')
freq_plot
glimpse(freq_plot)
df <- data.frame(month=names(freq_plot, frequency=freq_plot)
df <- data.frame(month=names(freq_plot, frequency=freq_plot))
df <- data.frame(month=names(freq_plot), frequency=freq_plot)
df
freq_plot <- c(4260, 210231, 95558, 37095, 16478, 7640, 13989, 7428)
df <- data.frame(Date=names(freq_plot), frequency=freq_plot)
freq_plot <- c(4260, 210231, 95558, 37095, 16478, 7640, 13989, 7428)
df <- data.frame(Date=names(freq_plot), frequency=freq_plot)
freq_plot <- c(4260, 210231, 95558, 37095, 16478, 7640, 13989, 7428)
names(freq_plot) <- c('Jul','Aug','Sep','Oct','Nov','Dec','Jan','Feb')
freq_plot
df <- data.frame(Date=names(freq_plot), frequency=freq_plot)
df
df <- data.frame(Date=names(freq_plot), freq_plot)
df
df <- data.frame(Date=names(freq_plot), Frequency=freq_plot)
df
ggplot(df, aes(Date, Frequency))+
geom_line+
labs(x = Date, y='',
title='Number of Tweets per Month')
library(ggplot2)
ggplot(df, aes(Date, Frequency))+
geom_line+
labs(x = Date, y='',
title='Number of Tweets per Month')
ggplot(df, aes(Date, Frequency))+
geom_line()+
labs(x = Date, y='',
title='Number of Tweets per Month')
df <- data.frame(Date=names(freq_plot), Frequency=freq_plot)
ggplot(df, aes(Date, Frequency))+
geom_line()+
labs(x = Date, y='',
title='Number of Tweets per Month')
df
ggplot(df, aes(x=Date, y=Frequency))+
geom_line()+
labs(x = Date, y='',
title='Number of Tweets per Month')
ggplot(df, aes(x='Date', y='Frequency'))+
geom_line()+
labs(x = Date, y='',
title='Number of Tweets per Month')
df$Date
ggplot(df, aes(Date, Frequency))+
geom_line()+
labs(x='Date', y='',
title='Number of Tweets per Month')
ggplot(df, aes(Frequency))+
geom_line()+
labs(x='Date', y='',
title='Number of Tweets per Month (2022 - 2023)')
ggplot(df, aes(Date, Frequency))+
geom_line()+
labs(x='Date', y='',
title='Number of Tweets per Month (2022 - 2023')
glimpse(df)
glimpse(df)
test <- [1:8]
test <- c([1:8])
ggplot(freq_plot, aes(x = freq_plot))+
geom_line()+
labs(x='Date', y='',
title='Number of Tweets per Month (2022 - 2023')
test <- 1:8
freq_plot <- c(4260, 210231, 95558, 37095, 16478, 7640, 13989, 7428)
names(freq_plot) <- c('Jul','Aug','Sep','Oct','Nov','Dec','Jan','Feb')
test <- 1:8
df <- data.frame(Date=names(freq_plot), Frequency=freq_plot, test)
df
m <- c('Jan','Feb','Mar','Apr','May','Jun',
'Jul','Aug','Sep','Oct','Nov','Dec')
ggplot(
df,(aes(test, Frequency, color=scale)))+
geom_point()+
geom_line()+
labs(x='', y='',
title='Number of Tweets per Month (2022 - 2023',
scale_y_continuous(limits=c(0,250000)))+
scale_x_discrete(limits=m)+
theme(legend.title = element_blank())
ggplot(
df,(aes(test, Frequency)))+
geom_point()+
geom_line()+
labs(x='', y='',
title='Number of Tweets per Month (2022 - 2023',
scale_y_continuous(limits=c(0,250000)))+
scale_x_discrete(limits=m)+
theme(legend.title = element_blank())
m <- c('Jul','Aug','Sep','Oct','Nov','Dec','Jan','Feb')
ggplot(
df,(aes(test, Frequency)))+
geom_point()+
geom_line()+
labs(x='', y='',
title='Number of Tweets per Month (2022 - 2023',
scale_y_continuous(limits=c(0,250000)))+
scale_x_discrete(limits=m)+
theme(legend.title = element_blank())
)
library(tidyverse)
setwd('~/UCF/Research/Quiet_Quitting/Twitter_data/CSV')
data <- read.csv('2022-Aug.csv')
names(data)
sort_like <- data[order(data$like_count, decreasing=T),]
head(sort_like$like_count)
head(sort_like$like_count, 20)
head(sort_like$text)
head(data$possibly_sensitive)
head(sort_like$possibly_sensitive)
head(sort_like$like_count, 30)
# export top liked tweets
export <- subset(sort_like, select=c(text, like_count, retweet_count))
glimpse(export)
head(export)
head(export$text)
# export top liked tweets
export <- head(subset(sort_like, select=c(text, like_count, retweet_count)), 30)
export
# export top liked tweets
export <- head(subset(sort_like, select=c(text, like_count, retweet_count)), 25)
export
write.csv(export, 'Aug-Top-Liked.csv')
library(magrittr)
unique(data$lang)
data %<>% filter(lang=='en')
unique(data$lang)
glimpse(data)
sort_like <- data[order(data$like_count, decreasing=T),]
head(sort_like$like_count, 30)
head(sort_like$text)
# export top liked tweets
export <- head(subset(sort_like, select=c(text, like_count, retweet_count)), 30)
# export top liked tweets
export <- head(subset(sort_like, select=c(text, like_count, retweet_count)), 30)
write.csv(export, 'Aug-Top-Liked.csv')
# let's try march (ND awareness week)
setwd('~/UCF/Research/Neurodiversity/NeurDi/raw_data/2023')
data <- read.csv('2023-Mar.csv', header=T)
sort_likes <- data[order(data$like_count, decreasing=T),]
head(sort_likes$like_count, 10)
head(sort_likes$text)
# export top liked tweets
export <- head(subset(sort_likes, select=c(text, like_count, retweet_count)), 30)
glimpse(export)
# export top liked tweets
export <- head(subset(sort_likes, select=c(text, like_count, retweet_count)), 30)
write.csv(export, 'Mar-Top-Liked.csv')
